{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "M9xFD31_oqFr",
        "WItoze9po-4y",
        "l4mfnxnDp4L_",
        "zzxJULEfo2js",
        "289lE4rzoSHs",
        "6leJVvwhnzWZ",
        "tnOS9afvV1oI",
        "8I1i7ko8qT_a",
        "A55d39FDqWgG"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parthusun8/pothole_detection/blob/main/Pothole_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BASIC IMPORTS AND DRIVE MOUNT"
      ],
      "metadata": {
        "id": "M9xFD31_oqFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from google.colab import files\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "fJOCM2R1tkPs"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('/content/data'):\n",
        "  !git clone 'https://github.com/parthusun8/pothole_detection' 'data'\n",
        "  !rm -rf '/content/data/assets'\n",
        "  !rm '/content/data/README.md'\n",
        "else:\n",
        "  print('DATASET ALREADY EXISTS')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJFNjCChmv0-",
        "outputId": "a873edab-81fb-433f-95a9-549764ac530e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATASET ALREADY EXISTS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODEL FITTING"
      ],
      "metadata": {
        "id": "KQLfe9nyot8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True,\n",
        "                                   validation_split=0.2)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "    directory=\"/content/data/train\",\n",
        "    target_size = (64, 64),\n",
        "    batch_size = 32,\n",
        "    class_mode = 'binary',\n",
        "    subset=\"training\")\n",
        "\n",
        "validation_set = train_datagen.flow_from_directory(\n",
        "    directory=\"/content/data/train\",\n",
        "    target_size = (64, 64),\n",
        "    batch_size = 32,\n",
        "    class_mode = 'binary',\n",
        "    subset=\"validation\"\n",
        ")"
      ],
      "metadata": {
        "id": "kc5Tcdma-PB2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba92c042-f996-4bb5-f6dc-b9a77f2f237a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 520 images belonging to 2 classes.\n",
            "Found 130 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TRAIN DATA SIZE -- 520 IMAGES IN TOTAL FROM NORMAL AND POTHOLE MIX\")\n",
        "print(\"VALIDATION DATA SIZE -- 130 IMAGES IN TOTAL FROM NORMAL AND POTHOLE MIX\")"
      ],
      "metadata": {
        "id": "J54ptdYH51Wi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "547241b6-ba45-46e7-85ab-cce27c40758d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN DATA SIZE -- 520 IMAGES IN TOTAL FROM NORMAL AND POTHOLE MIX\n",
            "VALIDATION DATA SIZE -- 130 IMAGES IN TOTAL FROM NORMAL AND POTHOLE MIX\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CREATING THE CNN LAYERS"
      ],
      "metadata": {
        "id": "YR0pBm01pEhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = None"
      ],
      "metadata": {
        "id": "yj45meDzoqTz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('/content/data/model.h5'):\n",
        "  cnn = tf.keras.models.Sequential()\n",
        "  cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
        "  cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "\n",
        "  cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "  cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "\n",
        "  cnn.add(tf.keras.layers.Flatten())\n",
        "\n",
        "  cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "\n",
        "  cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "  cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "  \n",
        "else:\n",
        "  cnn = tf.keras.models.load_model('model.h5')"
      ],
      "metadata": {
        "id": "gWE2ASeKdSWQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.summary()"
      ],
      "metadata": {
        "id": "_vNpPpYms6Wx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec337165-40a4-4aed-ab8e-da2fb4d2d721"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               802944    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 813,217\n",
            "Trainable params: 813,217\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL FITTING"
      ],
      "metadata": {
        "id": "kPmzAByNpCGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = None\n",
        "if not os.path.exists('/content/data/history.npy'):\n",
        "  history = cnn.fit(x = training_set, validation_data = validation_set, epochs = 20)\n",
        "  cnn.save(\"model.h5\")\n",
        "  np.save('history.npy',history.history)\n",
        "  files.download('history.npy')\n",
        "  files.download('model.h5')\n",
        "else:\n",
        "  history = np.load('history.npy',allow_pickle='TRUE').item()"
      ],
      "metadata": {
        "id": "UOkWhpJB1BeI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "427561ee-2961-49db-f7b9-5fe6e990384e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "17/17 [==============================] - 46s 3s/step - loss: 0.7352 - accuracy: 0.5038 - val_loss: 0.6724 - val_accuracy: 0.5231\n",
            "Epoch 2/20\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.6220 - accuracy: 0.6596"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODEL HISTORY PLOT"
      ],
      "metadata": {
        "id": "WItoze9po-4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## MODEL ACCURACY\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.savefig('model_accuracy.jpg')\n",
        "files.download('model_accuracy.jpg')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.savefig('model_loss.jpg')\n",
        "files.download('model_loss.jpg')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VueJY4SVZknR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODEL ARCHITECHTURE"
      ],
      "metadata": {
        "id": "l4mfnxnDp4L_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(cnn, to_file='model_arch.jpg', show_shapes=True)\n",
        "files.download('model_arch.jpg')"
      ],
      "metadata": {
        "id": "MARgdYc8p3IP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODEL EVALUATION, CONFUSION MATRIX, F1-SCORE"
      ],
      "metadata": {
        "id": "289lE4rzoSHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator = ImageDataGenerator()\n",
        "test_data_generator = test_generator.flow_from_directory(\n",
        "    \"/content/data/test\",\n",
        "     target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    shuffle=False)\n",
        "\n",
        "test_steps_per_epoch = np.math.ceil(test_data_generator.samples / test_data_generator.batch_size)\n",
        "\n",
        "predictions = cnn.predict(test_data_generator, steps=test_steps_per_epoch)\n",
        "# Get most likely class\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n"
      ],
      "metadata": {
        "id": "ekEaUpyl5ckV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(predictions)\n",
        "preds = []\n",
        "\n",
        "for pred in predictions:\n",
        "  preds.append(pred[0])\n",
        "\n",
        "print(preds)"
      ],
      "metadata": {
        "id": "LO_8r-H5CgK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GROUND TRUTH"
      ],
      "metadata": {
        "id": "eWffBHWFnqZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "true_classes = test_data_generator.classes #GROUND TRUTH\n",
        "class_labels = list(test_data_generator.class_indices.keys())\n",
        "print(true_classes)\n",
        "print(class_labels)"
      ],
      "metadata": {
        "id": "P6Zj9bYX9typ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONFUSION MATRIX"
      ],
      "metadata": {
        "id": "l0tJ3nqknnic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "cm = confusion_matrix(test_data_generator.classes, preds)\n",
        "cm\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.savefig('confusion_matrix.jpg')\n",
        "files.download(\"confusion_matrix.jpg\") \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MkXC-D7LAQwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "F1 SCORE"
      ],
      "metadata": {
        "id": "naRZnxfpnhgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test_data_generator.classes, preds))"
      ],
      "metadata": {
        "id": "OWMDJiXiDCWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CREATING TEST DATASET FOR DATA VISUALIZATION"
      ],
      "metadata": {
        "id": "6leJVvwhnzWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras.utils as image\n",
        "import cv2\n",
        "test_dataset = []\n",
        "for dirname, _, filenames in os.walk('/content/data/test'):\n",
        "  for filename in filenames:\n",
        "    imgFile = os.path.join(dirname, filename)\n",
        "    img = cv2.imread(imgFile)\n",
        "    img1 = image.load_img(imgFile, target_size = (64, 64))\n",
        "    img1 = image.img_to_array(img1)\n",
        "    img1 = np.expand_dims(img1, axis = 0)\n",
        "\n",
        "    label = dirname.split('/')[7]\n",
        "    \n",
        "    result = cnn.predict(img1)\n",
        "    prob = np.max(result, axis=1)\n",
        "    pred_per = prob * 100\n",
        "    prediction = 'potholes' if result[0][0] == 1 else 'normal'\n",
        "\n",
        "    test_dataset.append((img1, img, label, prediction, pred_per))"
      ],
      "metadata": {
        "id": "NIsilCMJNkc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_test_dataset_size = len(test_dataset)\n",
        "print(total_test_dataset_size)"
      ],
      "metadata": {
        "id": "O3afXP3tRAIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PLOT TEST DATASET WITH ACTUAL LABEL AND PREDICTED LABEL ALONG WITH PREDICTION PERCENTAGE"
      ],
      "metadata": {
        "id": "va2aYVgSn6AI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(nrows=total_test_dataset_size, ncols=1, figsize = (100, 100))\n",
        "i = 0\n",
        "for _, img, true_label, pred_label, prob in test_dataset:\n",
        "  title = f'Actual: {true_label.capitalize()}, Predicted: {pred_label.capitalize()}, Prediction Percentage: {prob[0]}%'\n",
        "  axs[i].imshow(img)\n",
        "  axs[i].set_title(title)\n",
        "\n",
        "  axs[i].set_xticks([])\n",
        "  axs[i].set_yticks([])\n",
        "\n",
        "  i+=1\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xLkWzy99QvDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FEATURE MAPS"
      ],
      "metadata": {
        "id": "tnOS9afvV1oI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer_names = [layer.name for layer in cnn.layers]\n",
        "layer_names"
      ],
      "metadata": {
        "id": "NitB0bWyV0qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_outputs = [layer.output for layer in cnn.layers]\n",
        "layer_outputs"
      ],
      "metadata": {
        "id": "ZGwZALL0V-_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_map_model = tf.keras.models.Model(cnn.input, layer_outputs)\n",
        "image_path= \"/content/data/test/potholes/319.jpg\"\n",
        "\n",
        "img = image.load_img(image_path, target_size = (64, 64))\n",
        "img = image.img_to_array(img)\n",
        "img = np.expand_dims(img, axis = 0)\n",
        "\n",
        "feature_maps = feature_map_model.predict(img)"
      ],
      "metadata": {
        "id": "KP3FGJ19WHq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "input_image = test_dataset[0][0] #CAN CHANGE INPUT IMAGE FOR DIFFERENT FEATURE MAPS\n",
        "\n",
        "for layer_name, feature_map in zip(layer_names, feature_maps):\n",
        "  # print(f\"The shape of the {layer_name} is =======>> {feature_map.shape}\")\n",
        "  if len(feature_map.shape) == 4 and feature_map.shape[3] == 32:\n",
        "    intermediate_layer_model = Model(cnn.input, cnn.get_layer(layer_name).output)\n",
        "    activations = intermediate_layer_model.predict(input_image)\n",
        "\n",
        "    # Plot the feature maps for the input image\n",
        "    title = f'Layer ===> {layer_name}'\n",
        "    plt.figure(figsize=(10,10))\n",
        "    \n",
        "    # plt.title(title)\n",
        "    for i in range(activations.shape[-1]):\n",
        "      if(i==1):\n",
        "        plt.title(title)\n",
        "      plt.subplot(7, 8, i+1)\n",
        "      plt.imshow(activations[0,:,:,i], cmap='viridis')\n",
        "      plt.axis('off')\n",
        "    plt.savefig(f'{layer_name}')\n",
        "    files.download(f'{layer_name}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "z2QeTp3JXB4S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}